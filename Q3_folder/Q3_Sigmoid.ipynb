{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c244e0-aa8e-4aa2-a4a5-054e4a3cd17e",
   "metadata": {},
   "source": [
    "# Q3: Effect of Activation Functions on CNN Performance  \n",
    "## Experiment: Sigmoid Activation\n",
    "\n",
    "This notebook investigates how the **Sigmoid activation function** affects the\n",
    "performance of a Convolutional Neural Network (CNN) on the Fashion-MNIST dataset.\n",
    "\n",
    "The goal of this experiment is to understand whether Sigmoid is suitable for\n",
    "deep convolutional architectures and to compare its behaviour with ReLU and\n",
    "LeakyReLU models trained under identical conditions.\n",
    "\n",
    "To ensure a **fair and controlled comparison**, all experimental settings\n",
    "(dataset, architecture, optimiser, learning rate, batch size, and number of\n",
    "epochs) are kept constant. The **only variable** changed is the activation\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18f8dd-cb01-40c4-8cb0-665bac562047",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "- **Dataset:** Fashion-MNIST (10 classes)\n",
    "- **Input:** 28 × 28 grayscale images\n",
    "- **Train / Validation split:** 80% / 20%\n",
    "\n",
    "### CNN Architecture\n",
    "- Conv2D: 1 → 8 filters, kernel size 3\n",
    "- MaxPooling: 2 × 2\n",
    "- Conv2D: 8 → 16 filters, kernel size 3\n",
    "- MaxPooling: 2 × 2\n",
    "- Fully connected layer: 128 units\n",
    "- Output layer: 10 units\n",
    "\n",
    "### Training Configuration\n",
    "- **Activation function:** LeakyReLU\n",
    "- **Loss function:** CrossEntropyLoss\n",
    "- **Optimiser:** Adam\n",
    "- **Learning rate:** 0.01\n",
    "- **Epochs:** 20\n",
    "\n",
    "All hyperparameters and architectural choices are consistent across activation\n",
    "function experiments to isolate the effect of the activation function itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a028329-9e77-48d4-b843-f72028f77846",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "We import PyTorch, supporting libraries, and helper functions defined in\n",
    "`functions.py`. These helper functions are shared across Q1, Q2, and Q3 to\n",
    "ensure consistency and reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11658bde-ee42-4f89-b1a8-15b464040f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:08.408137Z",
     "iopub.status.busy": "2025-12-18T23:32:08.407170Z",
     "iopub.status.idle": "2025-12-18T23:32:08.424301Z",
     "shell.execute_reply": "2025-12-18T23:32:08.420765Z",
     "shell.execute_reply.started": "2025-12-18T23:32:08.408057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from functions import get_data, data_split_train_val\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b369b-9964-4c0b-b401-fe8691160da3",
   "metadata": {},
   "source": [
    "## Dataset: Fashion-MNIST\n",
    "\n",
    "Fashion-MNIST consists of 28×28 grayscale images across 10 clothing categories.\n",
    "It is a commonly used benchmark dataset for image classification and is\n",
    "well-suited for analysing CNN behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ed30819-9ccd-49bb-aeaa-5247162f9543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:08.853061Z",
     "iopub.status.busy": "2025-12-18T23:32:08.852239Z",
     "iopub.status.idle": "2025-12-18T23:32:11.522476Z",
     "shell.execute_reply": "2025-12-18T23:32:11.519613Z",
     "shell.execute_reply.started": "2025-12-18T23:32:08.853002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8000, 784)\n",
      "Validation shape: (2000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion-MNIST (normalised to [0,1])\n",
    "X, y = get_data(\"../data/fashion-mnist_test.csv\")\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = data_split_train_val(X, y)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0db57-7450-4afc-82bf-70e58d1bf5fb",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The data is converted into PyTorch tensors and loaded using `DataLoader`.\n",
    "Mini-batch training improves optimisation stability and reflects standard\n",
    "deep learning practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da00cd34-3fd6-4e79-99d7-77ddd3be378b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.526636Z",
     "iopub.status.busy": "2025-12-18T23:32:11.525890Z",
     "iopub.status.idle": "2025-12-18T23:32:11.537392Z",
     "shell.execute_reply": "2025-12-18T23:32:11.535389Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.526580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5d22a8d-84a6-4856-a4cc-6505498d9fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.539779Z",
     "iopub.status.busy": "2025-12-18T23:32:11.539184Z",
     "iopub.status.idle": "2025-12-18T23:32:11.553891Z",
     "shell.execute_reply": "2025-12-18T23:32:11.551913Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.539727Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshape:\n",
      "X_train_tensor shape: torch.Size([8000, 784])\n",
      "X_val_tensor shape: torch.Size([2000, 784])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before reshape:\")\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"X_val_tensor shape:\", X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e55d220-b589-4c80-8e96-9bb7936e9f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.559501Z",
     "iopub.status.busy": "2025-12-18T23:32:11.558930Z",
     "iopub.status.idle": "2025-12-18T23:32:11.569619Z",
     "shell.execute_reply": "2025-12-18T23:32:11.567744Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.559433Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "num_train = X_train_tensor.shape[0]\n",
    "num_val = X_val_tensor.shape[0]\n",
    "\n",
    "print(num_train, num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bfc38f5-3fb6-45c7-b4b2-a15b3e9b7ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.572212Z",
     "iopub.status.busy": "2025-12-18T23:32:11.571604Z",
     "iopub.status.idle": "2025-12-18T23:32:11.582887Z",
     "shell.execute_reply": "2025-12-18T23:32:11.580927Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.572161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor reshape: torch.Size([8000, 1, 28, 28])\n",
      "X_val_tensor reshape: torch.Size([2000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = X_train_tensor.reshape(num_train, 1, 28, 28)\n",
    "X_val_tensor = X_val_tensor.reshape(num_val, 1, 28, 28)\n",
    "print(\"X_train_tensor reshape:\", X_train_tensor.shape)\n",
    "print(\"X_val_tensor reshape:\", X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4292cf91-669e-4d74-a5b1-3d7a70730b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.585267Z",
     "iopub.status.busy": "2025-12-18T23:32:11.584729Z",
     "iopub.status.idle": "2025-12-18T23:32:11.596512Z",
     "shell.execute_reply": "2025-12-18T23:32:11.594456Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.585216Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade367b-37e4-42c1-8e1b-3fbf6335e8d8",
   "metadata": {},
   "source": [
    "## CNN Architecture with Sigmoid Activation\n",
    "\n",
    "This CNN architecture matches the models used in the ReLU and LeakyReLU\n",
    "experiments. Sigmoid activation is applied after each convolutional layer\n",
    "and the first fully connected layer.\n",
    "\n",
    "The output layer does not apply an activation function, as\n",
    "`CrossEntropyLoss` expects raw logits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d7e7ac6-a62f-4f24-a09d-b3cc56ed32f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.598976Z",
     "iopub.status.busy": "2025-12-18T23:32:11.598388Z",
     "iopub.status.idle": "2025-12-18T23:32:11.613072Z",
     "shell.execute_reply": "2025-12-18T23:32:11.610952Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.598925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.conv1(x)))\n",
    "        x = self.pool(self.act(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26144b-29f7-4b60-9c6c-3d375f5edaff",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "The model is trained using the Adam optimiser and CrossEntropy loss.\n",
    "All hyperparameters are identical to those used in other activation\n",
    "function experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6d918a1-df53-41a5-9cec-0f7c712f0275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:11.840987Z",
     "iopub.status.busy": "2025-12-18T23:32:11.840333Z",
     "iopub.status.idle": "2025-12-18T23:32:11.865260Z",
     "shell.execute_reply": "2025-12-18T23:32:11.863716Z",
     "shell.execute_reply.started": "2025-12-18T23:32:11.840933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = CNN_Sigmoid()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(data.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c435a-0fb1-4bc9-bd74-9a805c886774",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Both training and validation loss and accuracy are recorded at each epoch\n",
    "to analyse learning behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fac4fe40-9508-45db-a288-d110bcea3f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:12.532047Z",
     "iopub.status.busy": "2025-12-18T23:32:12.531213Z",
     "iopub.status.idle": "2025-12-18T23:32:12.541531Z",
     "shell.execute_reply": "2025-12-18T23:32:12.539568Z",
     "shell.execute_reply.started": "2025-12-18T23:32:12.531988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ced23-227a-415b-9db5-0de956a061d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:12.963818Z",
     "iopub.status.busy": "2025-12-18T23:32:12.963116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 2.3280, Val Loss: 2.6788, Val Acc: 0.0960\n",
      "Epoch 2/20, Train Loss: 2.6839, Val Loss: 2.4338, Val Acc: 0.0980\n",
      "Epoch 3/20, Train Loss: 2.4367, Val Loss: 2.3397, Val Acc: 0.0965\n",
      "Epoch 4/20, Train Loss: 2.3405, Val Loss: 2.3301, Val Acc: 0.1025\n",
      "Epoch 5/20, Train Loss: 2.3297, Val Loss: 2.3361, Val Acc: 0.0960\n",
      "Epoch 6/20, Train Loss: 2.3350, Val Loss: 2.3367, Val Acc: 0.0960\n",
      "Epoch 7/20, Train Loss: 2.3355, Val Loss: 2.3304, Val Acc: 0.0960\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass (training)\n",
    "    outputs = data(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Training accuracy\n",
    "    train_preds = torch.argmax(outputs, 1)\n",
    "    train_acc = (train_preds == y_train_tensor).float().mean().item()\n",
    "    \n",
    "    # Validation loss and accuracy\n",
    "    with torch.no_grad():\n",
    "        val_outputs = data(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_preds = torch.argmax(val_outputs, 1)\n",
    "        val_acc = (val_preds == y_val_tensor).float().mean().item()\n",
    "    \n",
    "    # Store history\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs}, \"\n",
    "        f\"Train Loss: {loss.item():.4f}, \"\n",
    "        f\"Val Loss: {val_loss.item():.4f}, \"\n",
    "        f\"Val Acc: {val_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f6a6d-0d63-44a1-819a-a393e624695e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Final validation accuracy:\", val_accuracies[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6426625-c750-44e7-8f0f-c863774b59b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5b4f9-eb4f-4f93-9161-89dea1b9c802",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "The CNN using Sigmoid activation fails to learn meaningful features,\n",
    "achieving a validation accuracy close to **random guessing (~10%)**.\n",
    "\n",
    "This behaviour is expected due to the **vanishing gradient problem** associated\n",
    "with Sigmoid activations. As neuron inputs grow large in magnitude, the Sigmoid\n",
    "function saturates, producing near-zero gradients. This prevents effective\n",
    "weight updates in deeper layers, causing training to stall.\n",
    "\n",
    "The loss remains close to 2.30, which corresponds to the expected loss of a\n",
    "random classifier across 10 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3c387-5ca5-49ef-a71d-bb527d24b5bb",
   "metadata": {},
   "source": [
    "## Comparison with Other Activation Functions\n",
    "\n",
    "Compared to ReLU and LeakyReLU:\n",
    "- Sigmoid converges significantly more slowly\n",
    "- Gradients vanish in deeper layers\n",
    "- Classification accuracy remains near chance level\n",
    "\n",
    "These results empirically confirm why Sigmoid is no longer used in modern\n",
    "deep CNN architectures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f411d-c5d1-47e6-9b93-51262bb9deea",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This experiment demonstrates that Sigmoid activation is unsuitable for\n",
    "convolutional neural networks due to vanishing gradients and poor learning\n",
    "dynamics.\n",
    "\n",
    "When compared with ReLU and LeakyReLU, Sigmoid performs substantially worse,\n",
    "highlighting the importance of activation function choice in deep learning\n",
    "model design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93c8d8-9821-4f17-aaae-41cb8f60048f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
