{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9709caeb-a6f4-4513-9199-ca042a8e79e8",
   "metadata": {},
   "source": [
    "# Q3: Effect of Activation Functions on CNN Performance  \n",
    "## Experiment: LeakyReLU Activation\n",
    "\n",
    "This experiment evaluates the impact of the **LeakyReLU activation function** on the\n",
    "training dynamics and classification performance of a Convolutional Neural Network\n",
    "(CNN) applied to the Fashion-MNIST dataset.\n",
    "\n",
    "To ensure a **fair and controlled comparison**, all experimental conditions\n",
    "(network architecture, optimiser, learning rate, dataset split, and number of epochs)\n",
    "are kept identical to the ReLU, Sigmoid, and Tanh experiments.\n",
    "Only the activation function differs between models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03d44c-88a9-470a-bf8a-8b025ba52de3",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "- **Dataset:** Fashion-MNIST (10 classes)\n",
    "- **Input:** 28 × 28 grayscale images\n",
    "- **Train / Validation split:** 80% / 20%\n",
    "\n",
    "### CNN Architecture\n",
    "- Conv2D: 1 → 8 filters, kernel size 3\n",
    "- MaxPooling: 2 × 2\n",
    "- Conv2D: 8 → 16 filters, kernel size 3\n",
    "- MaxPooling: 2 × 2\n",
    "- Fully connected layer: 128 units\n",
    "- Output layer: 10 units\n",
    "\n",
    "### Training Configuration\n",
    "- **Activation function:** LeakyReLU\n",
    "- **Loss function:** CrossEntropyLoss\n",
    "- **Optimiser:** Adam\n",
    "- **Learning rate:** 0.01\n",
    "- **Epochs:** 20\n",
    "\n",
    "All hyperparameters and architectural choices are consistent across activation\n",
    "function experiments to isolate the effect of the activation function itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1e8a7f4-479b-4d1f-bc09-a72a53d54747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:23.549112Z",
     "iopub.status.busy": "2025-12-18T23:32:23.547162Z",
     "iopub.status.idle": "2025-12-18T23:32:23.656979Z",
     "shell.execute_reply": "2025-12-18T23:32:23.654158Z",
     "shell.execute_reply.started": "2025-12-18T23:32:23.549006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from functions import get_data, data_split_train_val\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ba7f3ac-b940-41ef-a08c-e4a1ca13a9e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:23.947113Z",
     "iopub.status.busy": "2025-12-18T23:32:23.946057Z",
     "iopub.status.idle": "2025-12-18T23:32:40.762240Z",
     "shell.execute_reply": "2025-12-18T23:32:40.759479Z",
     "shell.execute_reply.started": "2025-12-18T23:32:23.947037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8000, 784)\n",
      "Validation shape: (2000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion-MNIST (normalised to [0,1])\n",
    "X, y = get_data(\"../data/fashion-mnist_test.csv\")\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = data_split_train_val(X, y)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7ed654d-9145-44e3-bcc8-0d67305aab77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:40.842380Z",
     "iopub.status.busy": "2025-12-18T23:32:40.840317Z",
     "iopub.status.idle": "2025-12-18T23:32:40.864213Z",
     "shell.execute_reply": "2025-12-18T23:32:40.861575Z",
     "shell.execute_reply.started": "2025-12-18T23:32:40.842323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de6db233-b25d-4ffd-857e-b2ba13378425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:40.866936Z",
     "iopub.status.busy": "2025-12-18T23:32:40.866303Z",
     "iopub.status.idle": "2025-12-18T23:32:40.940100Z",
     "shell.execute_reply": "2025-12-18T23:32:40.876566Z",
     "shell.execute_reply.started": "2025-12-18T23:32:40.866882Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshape:\n",
      "X_train_tensor shape: torch.Size([8000, 784])\n",
      "X_val_tensor shape: torch.Size([2000, 784])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before reshape:\")\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"X_val_tensor shape:\", X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc1e4446-c761-4809-aad8-c1c06c3c01d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:40.945832Z",
     "iopub.status.busy": "2025-12-18T23:32:40.945164Z",
     "iopub.status.idle": "2025-12-18T23:32:40.967417Z",
     "shell.execute_reply": "2025-12-18T23:32:40.964795Z",
     "shell.execute_reply.started": "2025-12-18T23:32:40.945766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "num_train = X_train_tensor.shape[0]\n",
    "num_val = X_val_tensor.shape[0]\n",
    "\n",
    "print(num_train, num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "644a2ea7-68dc-4eed-9b16-4b5364807f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:40.970355Z",
     "iopub.status.busy": "2025-12-18T23:32:40.969806Z",
     "iopub.status.idle": "2025-12-18T23:32:40.984365Z",
     "shell.execute_reply": "2025-12-18T23:32:40.981950Z",
     "shell.execute_reply.started": "2025-12-18T23:32:40.970300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor reshape: torch.Size([8000, 1, 28, 28])\n",
      "X_val_tensor reshape: torch.Size([2000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = X_train_tensor.reshape(num_train, 1, 28, 28)\n",
    "X_val_tensor = X_val_tensor.reshape(num_val, 1, 28, 28)\n",
    "print(\"X_train_tensor reshape:\", X_train_tensor.shape)\n",
    "print(\"X_val_tensor reshape:\", X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e7a8ac1-69ad-4f46-9577-567b819f1d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:40.986914Z",
     "iopub.status.busy": "2025-12-18T23:32:40.986282Z",
     "iopub.status.idle": "2025-12-18T23:32:41.148715Z",
     "shell.execute_reply": "2025-12-18T23:32:41.145647Z",
     "shell.execute_reply.started": "2025-12-18T23:32:40.986861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d0cc9-279c-41c4-89e4-3af96ac98de5",
   "metadata": {},
   "source": [
    "## Model Architecture with LeakyReLU\n",
    "\n",
    "LeakyReLU is used after each convolutional and fully connected layer (except the output).\n",
    "Unlike standard ReLU, LeakyReLU allows a small, non-zero gradient for negative inputs,\n",
    "which helps mitigate the *dying ReLU* problem and improves gradient flow during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd332669-5efa-4a01-b1c6-10ac0f66adb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:41.151668Z",
     "iopub.status.busy": "2025-12-18T23:32:41.150901Z",
     "iopub.status.idle": "2025-12-18T23:32:41.256608Z",
     "shell.execute_reply": "2025-12-18T23:32:41.253821Z",
     "shell.execute_reply.started": "2025-12-18T23:32:41.151567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_LeakyReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(16*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.activation(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28254c59-07d6-47f0-b8d2-3b5cdb9cdcfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:41.346614Z",
     "iopub.status.busy": "2025-12-18T23:32:41.261243Z",
     "iopub.status.idle": "2025-12-18T23:32:41.444879Z",
     "shell.execute_reply": "2025-12-18T23:32:41.442237Z",
     "shell.execute_reply.started": "2025-12-18T23:32:41.346483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = CNN_LeakyReLU()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(data.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c8bf7a1-ef97-4c39-80b5-2d8063dc110d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:41.447986Z",
     "iopub.status.busy": "2025-12-18T23:32:41.447191Z",
     "iopub.status.idle": "2025-12-18T23:32:41.461364Z",
     "shell.execute_reply": "2025-12-18T23:32:41.459002Z",
     "shell.execute_reply.started": "2025-12-18T23:32:41.447905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4d9a7-21c4-4402-83d0-72ed633c7881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:32:41.542861Z",
     "iopub.status.busy": "2025-12-18T23:32:41.541087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 2.3025, Val Loss: 2.2439, Val Acc: 0.1650\n",
      "Epoch 2/20, Train Loss: 2.2435, Val Loss: 2.0904, Val Acc: 0.3085\n",
      "Epoch 3/20, Train Loss: 2.0898, Val Loss: 1.8328, Val Acc: 0.4765\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass (training)\n",
    "    outputs = data(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Training accuracy\n",
    "    train_preds = torch.argmax(outputs, 1)\n",
    "    train_acc = (train_preds == y_train_tensor).float().mean().item()\n",
    "    \n",
    "    # Validation loss and accuracy\n",
    "    with torch.no_grad():\n",
    "        val_outputs = data(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_preds = torch.argmax(val_outputs, 1)\n",
    "        val_acc = (val_preds == y_val_tensor).float().mean().item()\n",
    "    \n",
    "    # Store history\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs}, \"\n",
    "        f\"Train Loss: {loss.item():.4f}, \"\n",
    "        f\"Val Loss: {val_loss.item():.4f}, \"\n",
    "        f\"Val Acc: {val_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd5c64-413b-4291-a4a4-9f2a7f362d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Final validation accuracy:\", val_accuracies[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066a5a2-e37f-413f-ae2f-94d00a3e116d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b70f20-630c-49a6-ac5b-587056543b55",
   "metadata": {},
   "source": [
    "## Training and Validation Performance\n",
    "\n",
    "The training and validation loss curves show a consistent downward trend,\n",
    "indicating stable learning and effective optimisation.\n",
    "\n",
    "Validation accuracy increases steadily across epochs, reaching approximately **75%**\n",
    "by epoch 20. This suggests that the model generalises well to unseen validation data\n",
    "and does not suffer from severe overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a308ab-7b66-41a8-bac6-06a419239a5a",
   "metadata": {},
   "source": [
    "## Comparison with Other Activation Functions\n",
    "\n",
    "When compared to ReLU and Sigmoid models trained under identical conditions:\n",
    "\n",
    "- **LeakyReLU** demonstrates smoother convergence and more stable gradients.\n",
    "- It achieves higher validation accuracy than Sigmoid, which often suffers from\n",
    "  vanishing gradients in deeper networks.\n",
    "- Compared to standard ReLU, LeakyReLU reduces the risk of inactive neurons and\n",
    "  maintains learning even for negative activations.\n",
    "\n",
    "Overall, LeakyReLU provides a strong balance between training stability and\n",
    "classification performance in this CNN architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e533e01-0e8a-404e-855b-a8306e4bf3d3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This experiment shows that LeakyReLU is an effective activation function for CNNs\n",
    "trained on Fashion-MNIST. Its ability to preserve gradient flow for negative inputs\n",
    "results in faster convergence and improved validation accuracy compared to Sigmoid,\n",
    "and slightly more stable training than standard ReLU.\n",
    "\n",
    "These findings highlight the importance of activation function choice in deep\n",
    "learning model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7cd2c9-be1b-4f08-832b-0dd7ffcb59c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
